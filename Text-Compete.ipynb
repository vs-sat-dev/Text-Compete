{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom transformers import BertTokenizer, BertModel, logging\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import KFold\n\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.utils import shuffle\n\nimport re \nimport scipy\nfrom scipy import sparse\nfrom scipy.stats import rankdata\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\nimport nltk\nimport re\nfrom tqdm.auto import tqdm\n#from datasets import Dataset\nfrom transformers import PreTrainedTokenizerFast\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nimport time\nimport scipy.optimize as optimize\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth = 300\npd.options.display.max_columns = 100\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:17.637696Z","iopub.execute_input":"2022-02-07T13:31:17.638211Z","iopub.status.idle":"2022-02-07T13:31:27.472717Z","shell.execute_reply.started":"2022-02-07T13:31:17.638118Z","shell.execute_reply":"2022-02-07T13:31:27.471707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:27.475022Z","iopub.execute_input":"2022-02-07T13:31:27.475326Z","iopub.status.idle":"2022-02-07T13:31:29.312158Z","shell.execute_reply.started":"2022-02-07T13:31:27.47529Z","shell.execute_reply":"2022-02-07T13:31:29.311283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\ndf_test","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:29.313796Z","iopub.execute_input":"2022-02-07T13:31:29.314175Z","iopub.status.idle":"2022-02-07T13:31:29.397542Z","shell.execute_reply.started":"2022-02-07T13:31:29.31413Z","shell.execute_reply":"2022-02-07T13:31:29.396683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sample_submission = pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\ndf_sample_submission","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:29.400051Z","iopub.execute_input":"2022-02-07T13:31:29.400911Z","iopub.status.idle":"2022-02-07T13:31:29.426831Z","shell.execute_reply.started":"2022-02-07T13:31:29.400867Z","shell.execute_reply":"2022-02-07T13:31:29.425876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WeakLearner1:\n    def __init__(self):\n        self.vectorizer1 = None\n        self.vectorizer2 = None\n        self.model1 = None\n        self.model2 = None\n    \n    def fit(self):\n        df_regression = pd.read_csv(\"../input/jigsaw-regression-based-data/train_data_version2.csv\")\n        df = df_regression[['text', 'y']]\n\n        self.vectorizer1 = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=1, ngram_range=(2, 5) )\n        X = self.vectorizer1.fit_transform(df['text'])\n        z = df[\"y\"].values\n        y = np.around(z, decimals=2)\n\n        self.model1 = Ridge(alpha=0.5)\n        self.model1.fit(X, y)\n        \n        #--------------------------------------------------------------------------------------------------\n        \n        rud_df = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n        rud_df['y'] = rud_df[\"offensiveness_score\"] \n\n        df = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})\n        self.vectorizer2 = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=3, ngram_range=(3, 4) )\n        X = self.vectorizer2.fit_transform(df['text'])\n        z = df[\"y\"].values\n        y = np.around(z, decimals=1)\n        self.model2 = Ridge(alpha=0.5)\n        self.model2.fit(X, y)\n    \n    def predict(self, x):\n        df_scores = pd.DataFrame()\n        df_scores.index = range(len(x))\n        test = self.vectorizer1.transform(x['text_to_transform'])\n        jr_preds = self.model1.predict(test)\n        df_scores['score1'] = rankdata(jr_preds, method='ordinal')\n        \n        #--------------------------------------------------------------------\n        \n        test = self.vectorizer2.transform(x['text_to_transform'])\n        rud_preds = self.model2.predict(test)\n\n        df_scores['score2'] = rankdata(rud_preds, method='ordinal')\n        df_scores['score3'] = df_scores['score1'] + df_scores['score2']\n        df_scores['score4'] = rankdata(df_scores['score3'], method='ordinal')\n        \n        df_scores.index = x.index\n        \n        return df_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:29.428245Z","iopub.execute_input":"2022-02-07T13:31:29.428541Z","iopub.status.idle":"2022-02-07T13:31:29.446322Z","shell.execute_reply.started":"2022-02-07T13:31:29.428487Z","shell.execute_reply":"2022-02-07T13:31:29.445185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dummy_fun(doc):\n    return doc\n\n\nclass WeakLearner2:\n    def __init__(self, data):\n        self.data = data\n        self.regressor = None\n        self.tokenizer = None\n        self.vectorizer = None\n    \n    def fit(self):\n        cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\n        for category in cat_mtpl:\n            self.data[category] = self.data[category] * cat_mtpl[category]\n\n        self.data['score'] = self.data.loc[:, 'toxic':'identity_hate'].mean(axis=1)\n\n        self.data['y'] = self.data['score']\n\n        min_len = (self.data['y'] > 0).sum()  # len of toxic comments\n        df_y0_undersample = self.data[self.data['y'] == 0].sample(n=min_len, random_state=0)  # take non toxic comments\n        df_train_new = pd.concat([self.data[self.data['y'] > 0], df_y0_undersample])  # make new df\n\n        raw_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n        raw_tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n        raw_tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\n        special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n        trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)\n\n        dataset = Dataset.from_pandas(df_train_new[['comment_text']])\n\n        def get_training_corpus():\n            for i in range(0, len(dataset), 1000):\n                yield dataset[i : i + 1000][\"comment_text\"]\n\n        raw_tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n\n        self.tokenizer = PreTrainedTokenizerFast(\n            tokenizer_object=raw_tokenizer,\n            unk_token=\"[UNK]\",\n            pad_token=\"[PAD]\",\n            cls_token=\"[CLS]\",\n            sep_token=\"[SEP]\",\n            mask_token=\"[MASK]\",\n        )\n        \n        labels = df_train_new['y']\n        comments = df_train_new['comment_text']\n        tokenized_comments = self.tokenizer(comments.to_list())['input_ids']\n\n        self.vectorizer = TfidfVectorizer(\n            analyzer = 'word',\n            tokenizer = dummy_fun,\n            preprocessor = dummy_fun,\n            token_pattern = None)\n\n        comments_tr = self.vectorizer.fit_transform(tokenized_comments)\n\n        self.regressor = Ridge(random_state=42, alpha=0.8)\n        self.regressor.fit(comments_tr, labels)\n    \n    def predict(self, x):\n        texts = x['text_to_transform']\n        texts = self.tokenizer(texts.to_list())['input_ids']\n        texts = self.vectorizer.transform(texts)\n        \n        df_scores = pd.DataFrame()\n        df_scores.index = range(len(x))\n\n        df_scores['score5'] = self.regressor.predict(texts)\n        \n        df_scores.index = x.index\n        \n        return df_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:29.448753Z","iopub.execute_input":"2022-02-07T13:31:29.449118Z","iopub.status.idle":"2022-02-07T13:31:29.471578Z","shell.execute_reply.started":"2022-02-07T13:31:29.449051Z","shell.execute_reply":"2022-02-07T13:31:29.470694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\n\nclass WeakLearner3:\n    def __init__(self, data):\n        self.data = data\n        self.vectorizer = None\n        self.model = None\n        self.l_model = None\n        self.s_model = None\n    \n    def fit(self):\n        cat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n                    'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\n        for category in cat_mtpl:\n            self.data[category] = self.data[category] * cat_mtpl[category]\n\n        self.data['score'] = self.data.loc[:, 'toxic':'identity_hate'].sum(axis=1)\n\n        self.data['y'] = self.data['score']\n\n        min_len = (self.data['y'] > 0).sum()  # len of toxic comments\n        df_y0_undersample = self.data[self.data['y'] == 0].sample(n=min_len, random_state=201)  # take non toxic comments\n        df_train_new = pd.concat([self.data[self.data['y'] > 0], df_y0_undersample])  # make new df\n        self.data = self.data.rename(columns={'comment_text':'text'})\n\n\n        tqdm.pandas()\n        self.data['text'] = self.data['text'].progress_apply(text_cleaning)\n        df = self.data.copy()\n        df['y'].value_counts(normalize=True)\n        min_len = (df['y'] >= 0.1).sum()\n        df_y0_undersample = df[df['y'] == 0].sample(n=min_len * 2, random_state=402)\n        df = pd.concat([df[df['y'] >= 0.1], df_y0_undersample])\n        self.vectorizer = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))\n        X = self.vectorizer.fit_transform(df['text'])\n        self.model = Ridge(alpha=0.5)\n        self.model.fit(X, df['y'])\n        self.l_model = Ridge(alpha=1.)\n        self.l_model.fit(X, df['y'])\n        self.s_model = Ridge(alpha=2.)\n        self.s_model.fit(X, df['y'])\n    \n    def predict(self, x):\n        df_sub = x.copy()\n        df_sub['text'] = x['text_to_transform'].progress_apply(text_cleaning)\n        X_test = self.vectorizer.transform(df_sub['text'])\n        p1 = self.model.predict(X_test)\n        p2 = self.l_model.predict(X_test)\n        p3 = self.s_model.predict(X_test)\n        \n        df_scores = pd.DataFrame()\n        df_scores.index = range(len(x))\n        \n        df_scores['score6'] = p1\n        df_scores['score7'] = p2\n        df_scores['score8'] = p3\n        df_scores['score9'] = (p1 + p2 + p3) / 3.\n        \n        df_scores.index = x.index\n        \n        return df_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:29.473516Z","iopub.execute_input":"2022-02-07T13:31:29.475061Z","iopub.status.idle":"2022-02-07T13:31:29.499824Z","shell.execute_reply.started":"2022-02-07T13:31:29.474984Z","shell.execute_reply":"2022-02-07T13:31:29.498831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WeakLearner4:\n    def __init__(self):\n        self.vectorizer1 = None\n        self.vectorizer2 = None\n        self.regressor1 = None\n        self.regressor2 = None\n    \n    def fit(self):\n        ruddit_df = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n        ruddit = ruddit_df[[\"txt\", \"offensiveness_score\"]]\n\n        self.vectorizer1 = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (3,5))\n        tfv = self.vectorizer1.fit_transform(ruddit[\"txt\"])\n\n        X = tfv\n        Y = ruddit['offensiveness_score']\n        self.regressor1 = LinearRegression().fit(X, Y)\n        \n        #----------------------------------------------------------------------------------------\n\n        data2 = pd.read_csv(\"../input/jigsaw-regression-based-data/train_data_version2.csv\")\n        df2 = data2[['text', 'y']]\n        \n        self.vectorizer2 = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 5))\n        X = self.vectorizer2.fit_transform(df2['text'])\n        w = df2[\"y\"].values\n        y = np.around(w, decimals=2)\n\n        self.regressor2=Ridge(alpha=0.3)\n        self.regressor2.fit(X, y)\n    \n    def predict(self, x):\n        tfv_comments = self.vectorizer1.transform(x[\"text_to_transform\"])\n        pred1 = self.regressor1.predict(tfv_comments)\n\n        test = self.vectorizer2.transform(x['text_to_transform'])\n        pred2 = self.regressor2.predict(test)\n\n        df_scores = pd.DataFrame()\n        df_scores.index = range(len(x))\n        \n        df_scores[\"score10\"] = pred1\n        df_scores[\"score11\"] = pred2\n        df_scores[\"score12\"] = pred1 + pred2\n        \n        df_scores.index = x.index\n        \n        return df_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:29.501444Z","iopub.execute_input":"2022-02-07T13:31:29.502421Z","iopub.status.idle":"2022-02-07T13:31:29.518511Z","shell.execute_reply.started":"2022-02-07T13:31:29.502377Z","shell.execute_reply":"2022-02-07T13:31:29.517603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_imbalance(row):\n    toxity = row[2:].sum()\n    if toxity > 0:\n        return 1\n    else:\n        return 0\n\n\nBATCH_SIZE = 16\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nNUM_FOLDS = 3\n\n\nclass TextDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length, is_test=False):\n        super(TextDataset, self).__init__()\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.is_test = is_test\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        x = self.data.iloc[index, 1]\n        if self.is_test:\n            targets = torch.tensor(self.data.iloc[index, 0])\n        else:\n            targets = torch.tensor(self.data.iloc[index, -1])\n        \n        encoded = self.tokenizer(x, add_special_tokens=True, max_length=self.max_length,\n                                return_token_type_ids=False, padding='max_length',\n                                truncation=True, return_attention_mask=True,\n                                return_tensors='pt')\n        \n        input_ids = encoded['input_ids'].squeeze()\n        attention_mask = encoded['attention_mask'].squeeze()\n        \n        return input_ids, attention_mask, targets\n\n\nclass TextNet(nn.Module):\n    def __init__(self, bert_model):\n        super(TextNet, self).__init__()\n        self.bert_model = bert_model\n        self.fc = nn.Linear(768, 1)\n    \n    def forward(self, input_ids, attention_mask):\n        out = self.bert_model(input_ids, attention_mask, return_dict=True)['pooler_output']\n        return self.fc(out)\n\n\ndef train_epoch(model, train_loader, criterion, optimizer, DEVICE):\n    model.train()\n    \n    losses = []\n    \n    for data in tqdm(train_loader):\n        input_ids, attention_mask, targets = data\n        input_ids = input_ids.to(DEVICE)\n        attention_mask = attention_mask.to(DEVICE)\n        targets = targets.to(DEVICE)\n\n        output = model(input_ids, attention_mask)\n\n        loss = criterion(output.squeeze().float(), targets.float())\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        losses.append(loss.item())\n\n    return np.mean(losses)\n\n\ndef val_epoch(model, val_loader, criterion, df_scores, DEVICE):\n    model.eval()\n    \n    losses = []\n    \n    with torch.no_grad():\n        for data in tqdm(val_loader):\n            input_ids, attention_mask, targets = data\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n            targets = targets.to(DEVICE)\n\n            preds = model(input_ids, attention_mask).cpu().tolist()\n            df_scores.loc[current_ind:current_ind + len(preds) - 1, 'scores'] = preds\n            current_ind += len(preds)\n\n    return df_scores['scores']\n\n\ndef predict(model, test_loader, DEVICE, df_scores):\n    model.eval()\n    \n    current_ind = 0\n    \n    with torch.no_grad():\n        for data in tqdm(test_loader):\n            input_ids, attention_mask, _ = data\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n\n            preds = model(input_ids, attention_mask).cpu().tolist()\n            df_scores.loc[current_ind:current_ind + len(preds) - 1, 'scores'] = preds\n            current_ind += len(preds)\n    \n    #print(f'submission_data: {submission_data}')\n    \n    #submission_data.to_csv('submission.csv', index=False)\n    return df_scores['scores']\n\n\ndf_train['is_toxic'] = df_train.apply(check_imbalance, axis=1)\nsample_numb = len(df_train.loc[df_train['is_toxic'] == 0]) - len(df_train.loc[df_train['is_toxic'] == 1])\nnot_toxic_df = df_train.loc[df_train['is_toxic'] == 0].drop('is_toxic', axis=1).reset_index(drop=True)\ntoxic_df = df_train.loc[df_train['is_toxic'] == 1].sample(n=sample_numb, replace=True, random_state=0, axis=0).drop('is_toxic', axis=1).reset_index(drop=True)\n\noversampled_df = pd.concat([not_toxic_df.sample(len(toxic_df)), toxic_df], axis=0)\noversampled_df = shuffle(oversampled_df)\noversampled_df.index = range(len(oversampled_df))\n\ntokenizers = []\nbert_models = []\n\nkfold = KFold(n_splits=NUM_FOLDS, random_state=0, shuffle=True)\nfor fold, (trn_ind, val_ind) in enumerate(kfold.split(oversampled_df)):\n    oversampled_train = oversampled_df.loc[trn_ind]\n    oversampled_val = oversampled_df.loc[val_ind]\n\n    category_weights = {\n        'toxic': 0.32, \n        'severe_toxic': 1.5, \n        'obscene': 0.16, \n        'threat': 1.5, \n        'insult': 0.64, \n        'identity_hate': 1.5\n    }\n\n    for category, weight in category_weights.items():\n        oversampled_df[category] = oversampled_df[category] * weight\n\n    oversampled_train['scores'] = oversampled_train.drop(['id', 'comment_text'], axis=1).mean(axis=1)\n    oversampled_val['scores'] = oversampled_val.drop(['id', 'comment_text'], axis=1).mean(axis=1)\n\n    #tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    tokenizer = BertTokenizer.from_pretrained('../input/bert-uncased')\n\n    train_dataset = TextDataset(oversampled_train, tokenizer, max_length=256)\n    val_dataset = TextDataset(oversampled_val, tokenizer, max_length=256)\n\n    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n\n    #bert_model = BertModel.from_pretrained('bert-base-uncased')\n    bert_model = BertModel.from_pretrained('../input/bert-base-uncased')    \n    \n    EPOCHS = 1\n    LEARNING_RATE = 2e-5\n\n    criterion = nn.MSELoss()\n\n    model = TextNet(bert_model).to(DEVICE)\n    \n    test_scores = df_test[['comment_id']]\n    test_scores['scores'] = 0.0\n    \n    val_scores = oversampled_df[['id']]\n    val_scores['scores'] = 0.0\n    for i in range(NUM_FOLDS):\n        test_scores[f'scores{i+1}'] = 0.0\n        val_scores[f'scores{i+1}'] = 0.0\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n    best_val_loss = np.inf\n\n    for epoch in range(EPOCHS):\n        print(f'Epoch: {epoch+1}/{EPOCHS}')\n        print('-' * 10)\n\n        print('Training')\n        train_loss = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n        \n        print('Validating')\n        val_scores.loc[val_ind, f'scores{fold+1}'] = predict(model, val_loader, DEVICE, val_scores)\n    \n    tokenizers.append(tokenizer)\n    bert_models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:31:29.520394Z","iopub.execute_input":"2022-02-07T13:31:29.520699Z","iopub.status.idle":"2022-02-07T13:37:03.174289Z","shell.execute_reply.started":"2022-02-07T13:31:29.52066Z","shell.execute_reply":"2022-02-07T13:37:03.165533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(len(bert_models)):\n    test_dataset = TextDataset(df_test, tokenizers[fold], max_length=256, is_test=True)\n    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, pin_memory=True)\n    test_scores.loc[:, f'scores{fold+1}'] = predict(bert_models[fold], test_loader, DEVICE, test_scores)\n\ntest_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:37:03.17586Z","iopub.status.idle":"2022-02-07T13:37:03.176535Z","shell.execute_reply.started":"2022-02-07T13:37:03.176216Z","shell.execute_reply":"2022-02-07T13:37:03.176245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_scores['score13'] = 0.0\nfor i in range(NUM_FOLDS):\n    val_scores['score13'] += val_scores[f'scores{i+1}']\nval_scores['score13'] /= NUM_FOLDS\nval_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:37:03.182024Z","iopub.status.idle":"2022-02-07T13:37:03.182576Z","shell.execute_reply.started":"2022-02-07T13:37:03.182246Z","shell.execute_reply":"2022-02-07T13:37:03.182281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_scores['score13'] = 0.0\nfor i in range(NUM_FOLDS):\n    test_scores['score13'] += test_scores[f'scores{i+1}']\ntest_scores['score13'] /= NUM_FOLDS\ntest_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:37:03.187271Z","iopub.status.idle":"2022-02-07T13:37:03.188147Z","shell.execute_reply.started":"2022-02-07T13:37:03.1876Z","shell.execute_reply":"2022-02-07T13:37:03.187657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\nweak_learners_list1 = []\nweak_learners_list2 = []\nweak_learners_list3 = []\nweak_learners_list4 = []\n\npreds = pd.DataFrame()\npreds.index = df_train.index\n\nkfold = KFold(n_splits=5, random_state=0, shuffle=True)\nfor trn_ind, val_ind in kfold.split(df_train):\n    train = df_train.loc[trn_ind].copy()\n    val = df_train.loc[val_ind].copy().rename({'comment_text': 'text_to_transform'}, axis=1)\n    \n    weak_learner1 = WeakLearner1()\n    weak_learner2 = WeakLearner2(train.copy())\n    weak_learner3 = WeakLearner3(train.copy())\n    weak_learner4 = WeakLearner4()\n    \n    weak_learner1.fit()\n    preds.loc[val_ind, ['score1', 'score2', 'score3', 'score4']] = weak_learner1.predict(val)\n    weak_learners_list1.append(weak_learner1)\n    \n    weak_learner2.fit()\n    preds.loc[val_ind, ['score5']] = weak_learner2.predict(val)\n    weak_learners_list2.append(weak_learner2)\n    \n    weak_learner3.fit()\n    preds.loc[val_ind, ['score6', 'score7', 'score8', 'score9']] = weak_learner3.predict(val)\n    weak_learners_list3.append(weak_learner3)\n    \n    weak_learner4.fit()\n    preds.loc[val_ind, ['score10', 'score11', 'score12']] = weak_learner4.predict(val)\n    weak_learners_list4.append(weak_learner4)\n\npreds","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:37:03.191017Z","iopub.status.idle":"2022-02-07T13:37:03.191522Z","shell.execute_reply.started":"2022-02-07T13:37:03.191255Z","shell.execute_reply":"2022-02-07T13:37:03.191284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = {\n    'weight1': 0.00021541577371536526,\n    'weight2': 5.4136806364041875e-05,\n    'weight3': 7.054474871811384e-05,\n    'weight4': 0.0004950044846158598,\n    'weight5': 0.7095369414928109,\n    'weight6': 0.960770202502568,\n    'weight7': 0.981466744436168,\n    'weight8': 0.668985311802379,\n    'weight9': 0.5862471473960014,\n    'weight10': 0.8412784043394306,\n    'weight11': 0.9543552087526861,\n    'weight12': 0.9100233856490589\n}\n\nall_weights = p['weight1'] + p['weight2'] + p['weight3'] + p['weight4'] \\\n            + p['weight5'] + p['weight6'] + p['weight7'] + p['weight8'] \\\n            + p['weight9'] + p['weight10'] + p['weight11'] + p['weight12']\nweight1 = p['weight1'] / all_weights\nweight2 = p['weight2'] / all_weights\nweight3 = p['weight3'] / all_weights\nweight4 = p['weight4'] / all_weights\nweight5 = p['weight5'] / all_weights\nweight6 = p['weight6'] / all_weights\nweight7 = p['weight7'] / all_weights\nweight8 = p['weight8'] / all_weights\nweight9 = p['weight9'] / all_weights\nweight10 = p['weight10'] / all_weights\nweight11 = p['weight11'] / all_weights\nweight12 = p['weight12'] / all_weights\n\npreds['score1'] = preds['score1']*weight1/all_weights\npreds['score2'] = preds['score2']*weight2/all_weights\npreds['score3'] = preds['score3']*weight3/all_weights\npreds['score4'] = preds['score4']*weight4/all_weights\npreds['score5'] = preds['score5']*weight5/all_weights\npreds['score6'] = preds['score6']*weight6/all_weights\npreds['score7'] = preds['score7']*weight7/all_weights\npreds['score8'] = preds['score8']*weight8/all_weights\npreds['score9'] = preds['score9']*weight9/all_weights\npreds['score10'] = preds['score10']*weight10/all_weights\npreds['score11'] = preds['score11']*weight11/all_weights\npreds['score12'] = preds['score12']*weight12/all_weights\npreds['score13'] = val_scores['score13']","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:37:03.195291Z","iopub.status.idle":"2022-02-07T13:37:03.195838Z","shell.execute_reply.started":"2022-02-07T13:37:03.195547Z","shell.execute_reply":"2022-02-07T13:37:03.195576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom sklearn.metrics import mean_squared_error\n\n\ndef objective(trial, data, targets):\n    weight1 = trial.suggest_float(\"weight1\", 0.0, 1.0)\n    weight2 = trial.suggest_float(\"weight2\", 0.0, 1.0)\n    weight3 = trial.suggest_float(\"weight3\", 0.0, 1.0)\n    weight4 = trial.suggest_float(\"weight4\", 0.0, 1.0)\n    weight5 = trial.suggest_float(\"weight5\", 0.0, 1.0)\n    weight6 = trial.suggest_float(\"weight6\", 0.0, 1.0)\n    weight7 = trial.suggest_float(\"weight7\", 0.0, 1.0)\n    weight8 = trial.suggest_float(\"weight8\", 0.0, 1.0)\n    weight9 = trial.suggest_float(\"weight9\", 0.0, 1.0)\n    weight10 = trial.suggest_float(\"weight10\", 0.0, 1.0)\n    weight11 = trial.suggest_float(\"weight11\", 0.0, 1.0)\n    weight12 = trial.suggest_float(\"weight12\", 0.0, 1.0)\n    weight13 = trial.suggest_float(\"weight13\", 0.0, 1.0)\n    \n    all_weights = weight1 + weight2 + weight3 + weight4 + weight5 + weight6 + weight7 + weight8 + weight9 + weight10 + weight11 + weight12 + weight13\n    \n    preds = data['score1']*weight1/all_weights + data['score2']*weight2/all_weights + data['score3']*weight3/all_weights + data['score4']*weight4/all_weights \\\n          + data['score5']*weight5/all_weights + data['score6']*weight6/all_weights + data['score7']*weight7/all_weights + data['score8']*weight8/all_weights \\\n          + data['score9']*weight9/all_weights + data['score10']*weight10/all_weights + data['score11']*weight11/all_weights + data['score12']*weight12/all_weights \\\n          + data['score13']*weight13/all_weights\n    \n    return mean_squared_error(targets['score'], preds)\n\n\ncat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in cat_mtpl:\n    df_train[category] = df_train[category] * cat_mtpl[category]\n\ndf_train['score'] = df_train.loc[:, ['obscene', 'toxic', 'threat', 'insult', 'severe_toxic', 'identity_hate']].sum(axis=1)\n    \nobjective_func = lambda trials: objective(trials, preds, df_train)\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective_func, n_trials=1000)\n\np = study.best_trial.params\np","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:37:03.198098Z","iopub.status.idle":"2022-02-07T13:37:03.198667Z","shell.execute_reply.started":"2022-02-07T13:37:03.198346Z","shell.execute_reply":"2022-02-07T13:37:03.198376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_weights = p['weight1'] + p['weight2'] + p['weight3'] + p['weight4'] \\\n            + p['weight5'] + p['weight6'] + p['weight7'] + p['weight8'] \\\n            + p['weight9'] + p['weight10'] + p['weight11'] + p['weight12'] + p['weight13']\nweight1 = p['weight1'] / all_weights\nweight2 = p['weight2'] / all_weights\nweight3 = p['weight3'] / all_weights\nweight4 = p['weight4'] / all_weights\nweight5 = p['weight5'] / all_weights\nweight6 = p['weight6'] / all_weights\nweight7 = p['weight7'] / all_weights\nweight8 = p['weight8'] / all_weights\nweight9 = p['weight9'] / all_weights\nweight10 = p['weight10'] / all_weights\nweight11 = p['weight11'] / all_weights\nweight12 = p['weight12'] / all_weights\nweight13 = p['weight13'] / all_weights\n\ntest_preds = pd.DataFrame()\ntest_preds.index = df_test.index\nfor i in range(12):\n    test_preds[f'score{i+1}'] = 0.0\nfor fold in range(len(weak_learners_list1)):\n    df_scores = weak_learners_list1[fold].predict(df_test.rename({'text': 'text_to_transform'}, axis=1))\n    for column in df_scores.columns:\n        df_scores[column] /= len(weak_learners_list1)\n        test_preds[column] += df_scores[column]\n\nfor fold in range(len(weak_learners_list2)):\n    df_scores = weak_learners_list2[fold].predict(df_test.rename({'text': 'text_to_transform'}, axis=1))\n    for column in df_scores.columns:\n        df_scores[column] /= len(weak_learners_list2)\n        test_preds[column] += df_scores[column]\n\nfor fold in range(len(weak_learners_list3)):\n    df_scores = weak_learners_list3[fold].predict(df_test.rename({'text': 'text_to_transform'}, axis=1))\n    for column in df_scores.columns:\n        df_scores[column] /= len(weak_learners_list3)\n        test_preds[column] += df_scores[column]\n\nfor fold in range(len(weak_learners_list4)):\n    df_scores = weak_learners_list4[fold].predict(df_test.rename({'text': 'text_to_transform'}, axis=1))\n    for column in df_scores.columns:\n        df_scores[column] /= len(weak_learners_list4)\n        test_preds[column] += df_scores[column]\n\nsubmission_data = df_test[['comment_id']]\nsubmission_data['score'] = 0.0\n\nsubmission_data['score'] = test_preds['score1']*weight1 + test_preds['score2']*weight2 + test_preds['score3']*weight3 \\\n                         + test_preds['score4']*weight4 + test_preds['score5']*weight5 + test_preds['score6']*weight6 \\\n                         + test_preds['score7']*weight7 + test_preds['score8']*weight8 + test_preds['score9']*weight9 \\\n                         + test_preds['score10']*weight10 + test_preds['score11']*weight11 + test_preds['score12']*weight12 + test_scores['score13']*weight13\nsubmission_data.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T13:37:03.219076Z","iopub.status.idle":"2022-02-07T13:37:03.219725Z","shell.execute_reply.started":"2022-02-07T13:37:03.219439Z","shell.execute_reply":"2022-02-07T13:37:03.219468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}